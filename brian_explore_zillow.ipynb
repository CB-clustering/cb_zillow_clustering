{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0804ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from env import host, user, password\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import env\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "import scipy\n",
    "import sklearn.linear_model\n",
    "import sklearn.preprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import wrangle\n",
    "import viz_explore\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d9becb",
   "metadata": {},
   "source": [
    "### 1. Ask at least 5 questions about the data, keeping in mind that your target variable is logerror. e.g. Is logerror significantly different for properties in LA County vs Orange County vs Ventura County?\n",
    "\n",
    "### 2. Answer those questions through a mix of statistical tests and visualizations.\n",
    "\n",
    "### 3. Bonus: Compute the mean(logerror) by zipcode and the overall mean(logerror). Write a loop that will run a t-test between the overall mean and the mean for each zip code. We want to identify the zip codes where the error is significantly higher or lower than the expected error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fe13bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE WRANGLE FUNCTION PERFORMS THE FOLLOWIN, IN BROAD STROKES:\n",
    "# 1. Get the data via SQL query\n",
    "# 2. Clean and prep the data\n",
    "# 3. Encode the appropriate columns (only ['county'] for now)\n",
    "# 4. Split the data: train, validate, test and X_ vs y_ splits as well\n",
    "# 5. Scale the data (all train, validate and test, and all X_ and y_ splits are scaled)\n",
    "\n",
    "df, train, validate, test, X_train, y_train, X_validate, y_validate, X_test, y_test, \\\n",
    "train_scaled, X_train_scaled, y_train_scaled, validate_scaled, X_validate_scaled, \\\n",
    "y_validate_scaled, test_scaled, X_test_scaled, y_test_scaled \\\n",
    "= wrangle.wrangle_zillow()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "961581d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61427, 31)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e0894a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parcelid                 int64\n",
       "bathrooms              float64\n",
       "bedrooms               float64\n",
       "condition              float64\n",
       "sq_ft                  float64\n",
       "full_baths             float64\n",
       "latitude               float64\n",
       "longitude              float64\n",
       "lot_size               float64\n",
       "census_tract           float64\n",
       "city_id                float64\n",
       "zip                    float64\n",
       "rooms                  float64\n",
       "structure_value        float64\n",
       "tax_value              float64\n",
       "year_assessed          float64\n",
       "land_value             float64\n",
       "tax_amount             float64\n",
       "logerror               float64\n",
       "county                  object\n",
       "age                    float64\n",
       "sq_ft_per_bathroom     float64\n",
       "sq_ft_per_bedroom      float64\n",
       "sq_ft_per_room         float64\n",
       "has_half_bath            int64\n",
       "age_bin               category\n",
       "tax_rate               float64\n",
       "price_per_sq_ft        float64\n",
       "Los_Angeles              uint8\n",
       "Orange                   uint8\n",
       "Ventura                  uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147b8651",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for col in df.columns:\n",
    "#     print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f38956b",
   "metadata": {},
   "source": [
    "There may be a few duplicated parcel ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f53ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.lot_size.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595086b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423a2109",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.age.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca93eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.age.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbb1d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.age.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b184748",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.cut(df.age, bins=[0,20,40,80,120,200], labels = [1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8057c796",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 3))\n",
    "\n",
    "# List of columns\n",
    "\n",
    "cols = ['bathrooms', 'bedrooms', 'sq_ft', 'full_baths','lot_size','rooms', \n",
    "        'structure_value']\n",
    "\n",
    "for i, col in enumerate(cols):\n",
    "\n",
    "    # i starts at 0, but plot nos should start at 1\n",
    "    plot_number = i + 1 \n",
    "\n",
    "    # Create subplot.\n",
    "    plt.subplot(1,7, plot_number)\n",
    "\n",
    "    # Title with column name.\n",
    "    plt.title(col)\n",
    "\n",
    "    # Display histogram for column.\n",
    "    df[col].hist(bins=10, edgecolor='black')\n",
    "\n",
    "    # Hide gridlines.\n",
    "    plt.grid(False)\n",
    "\n",
    "    plt.tight_layout(),\n",
    "\n",
    "plt.figure(figsize=(16, 3))\n",
    "\n",
    "for i, col in enumerate(cols):\n",
    "\n",
    "    # i starts at 0, but plot nos should start at 1\n",
    "    plot_number = i + 1 \n",
    "\n",
    "    # Create subplot.\n",
    "    plt.subplot(1,7, plot_number)\n",
    "\n",
    "    # Title with column name.\n",
    "    plt.title(col)\n",
    "\n",
    "    # Display histogram for column.\n",
    "    plt.boxplot(df[col])\n",
    "\n",
    "    # Hide gridlines.\n",
    "    plt.grid(False)\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1350a97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 3))\n",
    "\n",
    "# List of columns\n",
    "\n",
    "cols = ['tax_value', 'year_assessed', 'land_value',\n",
    "       'tax_amount', 'logerror', 'age', 'sq_ft_per_bathroom']\n",
    "# col list from previous analysis...\n",
    "# cols = ['bedrooms', 'bathrooms','sq_ft','tax_value', 'age', 'sq_ft_per_bathroom']\n",
    "# Note the enumerate code, which is functioning to make a counter for use in successive plots.\n",
    "\n",
    "for i, col in enumerate(cols):\n",
    "\n",
    "    # i starts at 0, but plot nos should start at 1\n",
    "    plot_number = i + 1 \n",
    "\n",
    "    # Create subplot.\n",
    "    plt.subplot(1,7, plot_number)\n",
    "\n",
    "    # Title with column name.\n",
    "    plt.title(col)\n",
    "\n",
    "    # Display histogram for column.\n",
    "    df[col].hist(bins=10, edgecolor='black')\n",
    "\n",
    "    # Hide gridlines.\n",
    "    plt.grid(False)\n",
    "\n",
    "    plt.tight_layout(),\n",
    "\n",
    "plt.figure(figsize=(16, 3))\n",
    "\n",
    "for i, col in enumerate(cols):\n",
    "\n",
    "    # i starts at 0, but plot nos should start at 1\n",
    "    plot_number = i + 1 \n",
    "\n",
    "    # Create subplot.\n",
    "    plt.subplot(1,7, plot_number)\n",
    "\n",
    "    # Title with column name.\n",
    "    plt.title(col)\n",
    "\n",
    "    # Display histogram for column.\n",
    "    plt.boxplot(df[col])\n",
    "\n",
    "    # Hide gridlines.\n",
    "    plt.grid(False)\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ee6dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 3))\n",
    "\n",
    "# List of columns\n",
    "\n",
    "cols = ['sq_ft_per_bedroom', 'sq_ft_per_room', 'has_half_bath',\n",
    "       'Los_Angeles', 'Orange', 'Ventura']\n",
    "# col list from previous analysis...\n",
    "# cols = ['bedrooms', 'bathrooms','sq_ft','tax_value', 'age', 'sq_ft_per_bathroom']\n",
    "# Note the enumerate code, which is functioning to make a counter for use in successive plots.\n",
    "\n",
    "for i, col in enumerate(cols):\n",
    "\n",
    "    # i starts at 0, but plot nos should start at 1\n",
    "    plot_number = i + 1 \n",
    "\n",
    "    # Create subplot.\n",
    "    plt.subplot(1,7, plot_number)\n",
    "\n",
    "    # Title with column name.\n",
    "    plt.title(col)\n",
    "\n",
    "    # Display histogram for column.\n",
    "    df[col].hist(bins=10, edgecolor='black')\n",
    "\n",
    "    # Hide gridlines.\n",
    "    plt.grid(False)\n",
    "\n",
    "    plt.tight_layout(),\n",
    "\n",
    "plt.figure(figsize=(16, 3))\n",
    "\n",
    "for i, col in enumerate(cols):\n",
    "\n",
    "    # i starts at 0, but plot nos should start at 1\n",
    "    plot_number = i + 1 \n",
    "\n",
    "    # Create subplot.\n",
    "    plt.subplot(1,7, plot_number)\n",
    "\n",
    "    # Title with column name.\n",
    "    plt.title(col)\n",
    "\n",
    "    # Display histogram for column.\n",
    "    plt.boxplot(df[col])\n",
    "\n",
    "    # Hide gridlines.\n",
    "    plt.grid(False)\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016ea9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sq_ft_per_room.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9414de92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sq_ft_per_room.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b7fda7",
   "metadata": {},
   "source": [
    "There aree 13 homes with 2 half baths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cb8444",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[(df.bathrooms - df.full_baths) == 1.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308aa518",
   "metadata": {},
   "source": [
    "## Is there a time period that has a higher or lower log error?\n",
    "Bin the age group--ten bins? And see results.  Hue on county...if that makes a difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7852dd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='age', y='logerror', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9e69b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    data=train,\n",
    "    y='logerror',\n",
    "    x='age',\n",
    "    col=pd.cut(df.age, bins=[0,40,80,120,200]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8874af5a",
   "metadata": {},
   "source": [
    "Things look a little tighter on either end...the 40-60 and the 60-80 look like they have a wider distribution of logerror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f61d474",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.boxplot(x='age_bin', y='logerror', data= train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe76482",
   "metadata": {},
   "source": [
    "Still looks like there are more outliers in the middle, but this could be due to more data being available in those age bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994487fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=train, x= df[df.age_bin == pd.Interval(0, 40)].logerror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94a7d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1,4,1)\n",
    "sns.histplot(data=df, x= train[train.age_bin == pd.Interval(0, 40)].logerror)\n",
    "plt.title(\"0 to 40\")\n",
    "plt.subplot(1,4,2)\n",
    "sns.histplot(data=df, x= train[train.age_bin == pd.Interval(40,80)].logerror)\n",
    "plt.title(\"40 to 80\")\n",
    "plt.subplot(1,4,3)\n",
    "sns.histplot(data=df, x= train[train.age_bin == pd.Interval(80,120)].logerror)\n",
    "plt.title(\"80 to 120\")\n",
    "plt.subplot(1,4,4)\n",
    "sns.histplot(data=df, x= train[train.age_bin == pd.Interval(120,200)].logerror)\n",
    "plt.title(\"120 and up\")\n",
    "# plt.subplot(1,7,5)\n",
    "# sns.histplot(data=df, x= train[train.age_bin == pd.Interval(80, 100)].logerror)\n",
    "# plt.title(\"80 to 100\")\n",
    "# plt.subplot(1,7,6)\n",
    "# sns.histplot(data=df, x= train[train.age_bin == pd.Interval(100, 120)].logerror)\n",
    "# plt.title(\"100 to 120\")\n",
    "# plt.subplot(1,7,7)\n",
    "# sns.histplot(data=df, x= train[train.age_bin == pd.Interval(120, 200)].logerror)\n",
    "# plt.title(\"120 and Up\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d3db00",
   "metadata": {},
   "source": [
    "Looking at logerror by age_bin, they are generally normally distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b47d13",
   "metadata": {},
   "source": [
    "Maybe run an ANOVA test to see about the variances? \n",
    "\n",
    "First, Levene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa39525",
   "metadata": {},
   "outputs": [],
   "source": [
    "#H0: Variances are equal\n",
    "#Ha: Variances are not equal\n",
    "\n",
    "stats.levene(\n",
    "    train[train.age_bin == pd.Interval(0, 40)].logerror,\n",
    "    train[train.age_bin == pd.Interval(40,80)].logerror,\n",
    "    train[train.age_bin == pd.Interval(80,120)].logerror,\n",
    "    train[train.age_bin == pd.Interval(120,200)].logerror,\n",
    "#     train[train.age_bin == pd.Interval(80,100)].logerror,\n",
    "#     train[train.age_bin == pd.Interval(100,120)].logerror,\n",
    "#     train[train.age_bin == pd.Interval(120,200)].logerror\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ffe1c5",
   "metadata": {},
   "source": [
    "The results show that the null hypothesis is rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4236f3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train.age_bin == pd.Interval(0, 40)].logerror.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa061669",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train.age_bin == pd.Interval(120,200)].logerror.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1849b10",
   "metadata": {},
   "source": [
    "#### Anova testing of the logerror by age_bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf98542",
   "metadata": {},
   "source": [
    "Set Hypothesis\n",
    "- 𝐻0 : Population means of logerror (by age_bin) are equal\n",
    "- 𝐻𝑎 : Population means of logerror (by age_bin) are not all equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07ebb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell runs an ANOVA test on the different 'age_bins'\n",
    "# We are demonstrating statistically that the age correlates to the logerror\n",
    "f, p = stats.f_oneway(\n",
    "    train[train.age_bin == pd.Interval(0, 40)].logerror,\n",
    "    train[train.age_bin == pd.Interval(40,80)].logerror,\n",
    "    train[train.age_bin == pd.Interval(80,120)].logerror,\n",
    "    train[train.age_bin == pd.Interval(120,200)].logerror)\n",
    "          \n",
    "#     train[train.age_bin == pd.Interval(80,100)].logerror,\n",
    "#     train[train.age_bin == pd.Interval(100,120)].logerror,\n",
    "#     train[train.age_bin == pd.Interval(120,200)].logerror\n",
    "#\n",
    "f, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0b8480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting our alpha and returning a statemtent on the validity of the ANOVA test by comparing alpha to the resulting p-value\n",
    "\n",
    "alpha = 0.05\n",
    "if p < alpha:\n",
    "    print(\"We reject H_O\")\n",
    "else:\n",
    "    print(\"We fail to reject $H_{0}$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19cb9c8",
   "metadata": {},
   "source": [
    "#### The anova test shows I can proceed with the understanding that the average logerror is different depending on the age of the home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3894e1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3c0b1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.relplot(data=train, y='logerror', x='age', col='county')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9fa1ab",
   "metadata": {},
   "source": [
    "This relplot shows age and logerror by county; any dignificant differences between the counties aren't clear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e53208",
   "metadata": {},
   "source": [
    "### What about a relationship between tax_value and logerror? (also: are these related targets?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f67c66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=train.tax_value, y=train.logerror, data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ec626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=train.tax_value, y=train.logerror, data=train, hue='county', alpha=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7305388f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=train.tax_value, y=train.logerror, data=train, col='county', alpha=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6488d71f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train[train.county=='Los_Angeles'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90246b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train.county=='Orange'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e117118",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train.county=='Ventura'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4675d7",
   "metadata": {},
   "source": [
    "### No clear impressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5db235",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='tax_value', y='logerror', data=train, scatter_kws={'alpha':.2},hue='county')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41db55ad",
   "metadata": {},
   "source": [
    "### Look like perfectly flat trend lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9ae7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22255920",
   "metadata": {},
   "source": [
    "## Does the condition of the home have an impact on the logerror?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad95ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=train.condition,y=train.logerror, data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186f2c16",
   "metadata": {},
   "source": [
    "Ok, the logerror is off by more on the houses with a condition of 1 and 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4413157a",
   "metadata": {},
   "source": [
    "### An ANOVA test might be in order to show this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af42a85",
   "metadata": {},
   "source": [
    "First, a Levene test to check on variances:\n",
    "\n",
    "#H0: Variances are equal\n",
    "#Ha: Variances are not equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313a6604",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train['condition'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5393401c",
   "metadata": {},
   "source": [
    "Roughly normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3315db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Levene test for equal variances...they aren't equal\n",
    "stats.levene(train.condition==1,train.condition==3,train.condition==4,train.condition==5,\n",
    "            train.condition==6,train.condition==7,train.condition==8,train.condition==9,\n",
    "            train.condition==10, train.condition==11,train.condition==12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8e3f68",
   "metadata": {},
   "source": [
    "Set Hypothesis (for the ANOVA test)\n",
    "- 𝐻0 : Population means of logerror (by condition) are equal\n",
    "- 𝐻𝑎 : Population means of logerror (by condition) are not all equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0180d2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the anova test:\n",
    "f, p = stats.f_oneway(train.condition==1,train.condition==3,train.condition==4,train.condition==5,\n",
    "            train.condition==6,train.condition==7,train.condition==8,train.condition==9,\n",
    "            train.condition==10, train.condition==11,train.condition==12)\n",
    "f,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44186205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting our alpha and returning a statemtent on the validity of the ANOVA test by comparing alpha to the resulting p-value\n",
    "\n",
    "alpha = 0.05\n",
    "if p < alpha:\n",
    "    print(\"We reject H_O\")\n",
    "else:\n",
    "    print(\"We fail to reject $H_{0}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87832952",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=train.rooms,y=train.logerror, data=train)\n",
    "plt.tight_layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bba118",
   "metadata": {},
   "source": [
    "## OK, let's answer a simple question for now:\n",
    "\n",
    "## Does (or...how does?) logerror differ by county?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5ce8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=train.county, y=train.logerror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f16992",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=train.county, y=train.logerror)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a79ef6",
   "metadata": {},
   "source": [
    "### Running a nope, also an ANOVA to check on this\n",
    "\n",
    "H_0: Average logerror of the three counties is the same\n",
    "\n",
    "\n",
    "H_a: The logerror is different according to county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78da7b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumptions: independence, yes.  Normal: yes (also large sample). Variances....\n",
    "train.Orange.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545b8d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Los_Angeles.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0034a160",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Ventura.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cc8b80",
   "metadata": {},
   "source": [
    "Definitely different variances, so set that in the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a0a623",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,p = scipy.stats.f_oneway(train.Orange,train.Los_Angeles,train.Ventura)\n",
    "f,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c3f00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting our alpha and returning a statemtent on the validity of the ANOVA test by comparing alpha to the resulting p-value\n",
    "\n",
    "alpha = 0.05\n",
    "if p < alpha:\n",
    "    print(\"We reject H_O\")\n",
    "else:\n",
    "    print(\"We fail to reject $H_{0}$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66077d1",
   "metadata": {},
   "source": [
    "And thus, we conclude that the means of the different logerrors by county are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d418f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdd5477",
   "metadata": {},
   "source": [
    "## Does my whole theory about half bathrooms bear out??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e991b7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=train.has_half_bath,y=train.logerror)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125c14c2",
   "metadata": {},
   "source": [
    "OK, well there is some difference, for what it's worth...proceeding to stats testing via one sided, independent t test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e64292",
   "metadata": {},
   "source": [
    "First: assumptions:\n",
    "\n",
    "- Normally distributed....mmm basically yes and many observations\n",
    "- Independence: check\n",
    "- Variances...are almost equal actually\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221e6f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.has_half_bath.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a55d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_half_bath_sample = train[train.has_half_bath == 1].logerror\n",
    "\n",
    "has_half_bath_sample.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8039c0f",
   "metadata": {},
   "source": [
    "Note how there are some examples that are wildly off in their logerror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea06c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_half_bath_sample.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cebc91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_half_bath_sample = train[train.has_half_bath==0].logerror\n",
    "no_half_bath_sample.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce164f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_half_bath_sample.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3add980",
   "metadata": {},
   "source": [
    "Set Hypothesis\n",
    "\n",
    "H_0\n",
    ": Mean of logerror of has_half_bath = Mean of logerror of no_half_bath\n",
    "\n",
    "H_a\n",
    ": Mean of logerror of has_half_bath != Mean of logerror of no_half_bath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716d2fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "t, p = stats.ttest_ind(has_half_bath_sample, no_half_bath_sample, equal_var=True)\n",
    "\n",
    "t, p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd21c964",
   "metadata": {},
   "source": [
    "p is NOT less than alpha (0.05), and therefore I cannot reject the Null Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281fa406",
   "metadata": {},
   "source": [
    "### So, having a half bathroom does not affect logerror.  Not directly for sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f317cc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8c2979",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
