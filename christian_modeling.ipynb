{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8380fb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from env import host, user, password\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import env\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "import scipy\n",
    "import sklearn.linear_model\n",
    "import sklearn.preprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import wrangle\n",
    "import viz_explore\n",
    "import scipy.stats as stats\n",
    "import brian_model\n",
    "import cluster_model\n",
    "import brian_feature_engineering\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.linear_model\n",
    "import sklearn.preprocessing\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc23be5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, train, validate, test, X_train, y_train, X_validate, y_validate, X_test, y_test, \\\n",
    "train_scaled, X_train_scaled, y_train_scaled, validate_scaled, X_validate_scaled, \\\n",
    "y_validate_scaled, test_scaled, X_test_scaled, y_test_scaled \\\n",
    "= wrangle.wrangle_zillow()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01c4389b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bathrooms', 'bedrooms', 'condition', 'sq_ft', 'full_baths', 'latitude',\n",
       "       'longitude', 'lot_size', 'rooms', 'structure_value', 'tax_value',\n",
       "       'year_assessed', 'land_value', 'tax_amount', 'age',\n",
       "       'sq_ft_per_bathroom', 'sq_ft_per_bedroom', 'sq_ft_per_room',\n",
       "       'has_half_bath', 'tax_rate', 'price_per_sq_ft', 'Los_Angeles', 'Orange',\n",
       "       'Ventura'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c45976a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell runs my function in feature_engineering.py that selects for the top 'k' number \n",
    "# of features\n",
    "#f_feature = brian_feature_engineering.select_kbest(X_train_scaled,y_train_scaled, 5)\n",
    "#f_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a28626c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_long_sf_train = X_train_scaled[['sq_ft', 'tax_rate', 'longitude']]\n",
    "_long_sf_validate = X_validate_scaled[['sq_ft', 'tax_rate', 'longitude']]\n",
    "_long_sf_test = X_test_scaled[['sq_ft', 'tax_rate', 'longitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aefe46e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, ..., 0, 3, 2], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearn implementation of KMeans\n",
    "\n",
    "#define the thing\n",
    "kmeans_long_sf = KMeans(n_clusters=4, random_state = 123, verbose = 0)\n",
    "\n",
    "# fit the thing\n",
    "kmeans_long_sf.fit(_long_sf_train)\n",
    "\n",
    "# Use (predict using) the thing \n",
    "kmeans_long_sf.predict(_long_sf_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e33ac96",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c74cc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled['log_sf_cluster'] = kmeans_long_sf.predict(_long_sf_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "902928d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled['log_sf_cluster'] = np.where(X_train_scaled.log_sf_cluster == 0,'small_low_to_medtax',np.where(X_train_scaled.log_sf_cluster == 1,'larger_lo_to_medtax',\\\n",
    "        np.where(X_train_scaled.log_sf_cluster == 2, 'all_size_low_to_midtax',\\\n",
    "                 'all_size_mid_to_hg_tax')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcaeae96",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate_scaled['log_sf_cluster'] = kmeans_long_sf.predict(_long_sf_validate)\n",
    "X_validate_scaled['log_sf_cluster'] = np.where(X_validate_scaled.log_sf_cluster == 0,'small_low_to_medtax',np.where(X_validate_scaled.log_sf_cluster == 1,'larger_lo_to_medtax',\\\n",
    "        np.where(X_validate_scaled.log_sf_cluster == 2, 'all_size_low_to_midtax',\\\n",
    "                 'all_size_mid_to_hg_tax')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "851e6ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled['log_sf_cluster'] = kmeans_long_sf.predict(_long_sf_test)\n",
    "X_test_scaled['log_sf_cluster'] = np.where(X_test_scaled.log_sf_cluster == 0,'small_low_to_medtax',np.where(X_test_scaled.log_sf_cluster == 1,'larger_lo_to_medtax',\\\n",
    "        np.where(X_test_scaled.log_sf_cluster == 2, 'all_size_low_to_midtax',\\\n",
    "                 'all_size_mid_to_hg_tax')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcb00181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is also in the cluster_model.py file\n",
    "\n",
    "def encode_clusters(df,cluster):\n",
    "    '''\n",
    "    This is encoding the cluster column for later modelling; it drops the original column \n",
    "    once it has been encoded\n",
    "    \n",
    "    '''\n",
    "    # ordinal encoder? sklearn.OrdinalEncoder\n",
    "\n",
    "    # I had originally put the columns to be dummied inside the function. They are now in the inputs\n",
    "    # cols_to_dummy = df['county']\n",
    "    # df = pd.get_dummies(df, columns=['county'], dummy_na=False, drop_first=False)\n",
    "        \n",
    "    dummy_df = pd.get_dummies(df[cluster], dummy_na=False, drop_first=False)\n",
    "\n",
    "    # Not requiring me to concatenate for some reason here.  \n",
    "    df = pd.concat([df, dummy_df], axis = 1)\n",
    "#     df = df.rename(columns={'county_Los_Angeles':'Los_Angeles','county_Orange':'Orange','county_Ventura':'Ventura'})\n",
    "    df = df.drop(columns='log_sf_cluster')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bb7af67",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = encode_clusters(X_train_scaled,['log_sf_cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cedebbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate_scaled = encode_clusters(X_validate_scaled,['log_sf_cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e46bf7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = encode_clusters(X_test_scaled,['log_sf_cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0ac71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be71353e",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8dc96b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10434c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logerror_pred_mean = y_train_scaled.logerror.mean()\n",
    "y_train_scaled['logerror_pred_mean'] = round(logerror_pred_mean, 5)\n",
    "y_validate_scaled['logerror_pred_mean'] = round(logerror_pred_mean,5)\n",
    "y_test_scaled['logerror_pred_mean'] = round(logerror_pred_mean,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb8c6cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE using Mean\n",
      "Train/In-Sample:  0.01897 \n",
      "Validate/Out-of-Sample:  0.01899\n"
     ]
    }
   ],
   "source": [
    "rmse_train = mean_squared_error(y_train_scaled.logerror,\n",
    "                                y_train_scaled.logerror_pred_mean) ** .5\n",
    "rmse_validate = mean_squared_error(y_validate_scaled.logerror, y_validate_scaled.logerror_pred_mean) ** (0.5)\n",
    "\n",
    "print(\"RMSE using Mean\\nTrain/In-Sample: \", round(rmse_train, 5), \n",
    "      \"\\nValidate/Out-of-Sample: \", round(rmse_validate, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "660218d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>RMSE_validate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean_baseline</td>\n",
       "      <td>0.018968</td>\n",
       "      <td>0.018994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  RMSE_train  RMSE_validate\n",
       "0  mean_baseline    0.018968       0.018994"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taken in by the modeling function below and expanded on.\n",
    "metric_df = pd.DataFrame(data=[\n",
    "            {\n",
    "                'model': 'mean_baseline', \n",
    "                'RMSE_train': rmse_train,\n",
    "                'RMSE_validate': rmse_validate\n",
    "                }\n",
    "            ])\n",
    "metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3f4db7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute adjusted R-squared\n",
    "def adj_r2_score(predictors, targets, predictions):\n",
    "    r2 = r2_score(targets, predictions)\n",
    "    n = predictors.shape[0]\n",
    "    k = predictors.shape[1]\n",
    "    return 1 - ((1 - r2) * (n - 1) / (n - k - 1))\n",
    "\n",
    "\n",
    "# function to compute MAPE\n",
    "def mape_score(targets, predictions):\n",
    "    return np.mean(np.abs(targets - predictions) / targets) * 100\n",
    "\n",
    "\n",
    "# function to compute different metrics to check performance of a regression model\n",
    "def model_performance_regression(model, predictors, target):\n",
    "    \"\"\"\n",
    "    Function to compute different metrics to check regression model performance\n",
    "\n",
    "    model: regressor\n",
    "    predictors: independent variables\n",
    "    target: dependent variable\n",
    "    \"\"\"\n",
    "\n",
    "    # predicting using the independent variables\n",
    "    pred = model.predict(predictors)\n",
    "\n",
    "    # computing the actual prices by using the exponential function\n",
    "    target = np.exp(target)\n",
    "    pred = np.exp(pred)\n",
    "\n",
    "    r2 = r2_score(target, pred)  # to compute R-squared\n",
    "    adjr2 = adj_r2_score(predictors, target, pred)  # to compute adjusted R-squared\n",
    "    rmse = np.sqrt(mean_squared_error(target, pred))  # to compute RMSE\n",
    "\n",
    "        \n",
    "\n",
    "    # creating a dataframe of metrics\n",
    "    df_perf = pd.DataFrame(\n",
    "        {\n",
    "            \"RMSE\": rmse,\n",
    "            \"R-squared\": r2,\n",
    "            \"Adj. R-squared\": adjr2\n",
    "        },\n",
    "        index=[0],\n",
    "    )\n",
    "\n",
    "    return df_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ed560e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb7fbd05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['logerror', 'logerror_pred_mean'], dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_scaled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6a27e756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting a linear model\n",
    "lin_reg_model = LinearRegression()\n",
    "lin_reg_model.fit(X_train_scaled, y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "29c39426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train performance\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R-squared</th>\n",
       "      <th>Adj. R-squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025645</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>0.000434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RMSE  R-squared  Adj. R-squared\n",
       "0  0.025645   0.001697        0.000434"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train performance')\n",
    "lin_reg_model_perf_train = model_performance_regression(lin_reg_model, X_train_scaled, y_train_scaled)\n",
    "lin_reg_model_perf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3607552e",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dd283082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate Performance:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R-squared</th>\n",
       "      <th>Adj. R-squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025137</td>\n",
       "      <td>0.375639</td>\n",
       "      <td>0.373793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RMSE  R-squared  Adj. R-squared\n",
       "0  0.025137   0.375639        0.373793"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Validate Performance:\")\n",
    "lin_reg_model_perf_test = model_performance_regression(lin_reg_model, X_validate_scaled, y_validate_scaled)\n",
    "lin_reg_model_perf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2a076425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Performance:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R-squared</th>\n",
       "      <th>Adj. R-squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.024777</td>\n",
       "      <td>0.376168</td>\n",
       "      <td>0.373953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RMSE  R-squared  Adj. R-squared\n",
       "0  0.024777   0.376168        0.373953"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Test Performance:\")\n",
    "lin_reg_model2_perf_test = model_performance_regression(lin_reg_model, X_test_scaled, y_test_scaled)\n",
    "lin_reg_model2_perf_test\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930296fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
