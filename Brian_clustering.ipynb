{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "172c944f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8b133bece7e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mviz_explore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'model'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from env import host, user, password\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import env\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "import scipy\n",
    "import sklearn.linear_model\n",
    "import sklearn.preprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import wrangle\n",
    "import viz_explore\n",
    "import scipy.stats as stats\n",
    "import model\n",
    "\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211e65a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE WRANGLE FUNCTION PERFORMS THE FOLLOWIN, IN BROAD STROKES:\n",
    "# 1. Get the data via SQL query\n",
    "# 2. Clean and prep the data\n",
    "# 3. Encode the appropriate columns (only ['county'] for now)\n",
    "# 4. Split the data: train, validate, test and X_ vs y_ splits as well\n",
    "# 5. Scale the data (all train, validate and test, and all X_ and y_ splits are scaled)\n",
    "\n",
    "df, train, validate, test, X_train, y_train, X_validate, y_validate, X_test, y_test, \\\n",
    "train_scaled, X_train_scaled, y_train_scaled, validate_scaled, X_validate_scaled, \\\n",
    "y_validate_scaled, test_scaled, X_test_scaled, y_test_scaled \\\n",
    "= wrangle.wrangle_zillow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107b7146",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae64d8bf",
   "metadata": {},
   "source": [
    "# CLUSTERING ON THE FOLLOWING VARIABLES:\n",
    "- sq_ft, price_per_sq_ft, tax_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af60bab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_scaled.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20802949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of variables I will cluster on. \n",
    "cluster_vars = ['sq_ft', 'price_per_sq_ft', 'tax_rate']\n",
    "cluster_name = 'good_deal_or_not_?'\n",
    "k_range = range(2,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db159f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_k(X_train_scaled, cluster_vars, k_range):\n",
    "#     sse = []\n",
    "#     for k in k_range:\n",
    "#         kmeans = KMeans(n_clusters=k)\n",
    "\n",
    "#         # X[0] is our X_train dataframe..the first dataframe in the list of dataframes stored in X. \n",
    "#         kmeans.fit(X_train[cluster_vars])\n",
    "\n",
    "#         # inertia: Sum of squared distances of samples to their closest cluster center.\n",
    "#         sse.append(kmeans.inertia_) \n",
    "\n",
    "#     # compute the difference from one k to the next\n",
    "#     delta = [round(sse[i] - sse[i+1],0) for i in range(len(sse)-1)]\n",
    "\n",
    "#     # compute the percent difference from one k to the next\n",
    "#     pct_delta = [round(((sse[i] - sse[i+1])/sse[i])*100, 1) for i in range(len(sse)-1)]\n",
    "\n",
    "#     # create a dataframe with all of our metrics to compare them across values of k: SSE, delta, pct_delta\n",
    "#     k_comparisons_df = pd.DataFrame(dict(k=k_range[0:-1], \n",
    "#                              sse=sse[0:-1], \n",
    "#                              delta=delta, \n",
    "#                              pct_delta=pct_delta))\n",
    "\n",
    "#     # plot k with inertia\n",
    "#     plt.plot(k_comparisons_df.k, k_comparisons_df.sse, 'bx-')\n",
    "#     plt.xlabel('k')\n",
    "#     plt.ylabel('SSE')\n",
    "#     plt.title('The Elbow Method to find the optimal k\\nFor which k values do we see large decreases in SSE?')\n",
    "#     plt.show()\n",
    "\n",
    "#     # plot k with pct_delta\n",
    "#     plt.plot(k_comparisons_df.k, k_comparisons_df.pct_delta, 'bx-')\n",
    "#     plt.xlabel('k')\n",
    "#     plt.ylabel('Percent Change')\n",
    "#     plt.title('For which k values are we seeing increased changes (%) in SSE?')\n",
    "#     plt.show()\n",
    "\n",
    "#     # plot k with delta\n",
    "#     plt.plot(k_comparisons_df.k, k_comparisons_df.delta, 'bx-')\n",
    "#     plt.xlabel('k')\n",
    "#     plt.ylabel('Absolute Change in SSE')\n",
    "#     plt.title('For which k values are we seeing increased changes (absolute) in SSE?')\n",
    "#     plt.show()\n",
    "\n",
    "#     return k_comparisons_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0c3300",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.find_k(X_train_scaled, cluster_vars, k_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43eb1fd",
   "metadata": {},
   "source": [
    "# Looks like k=5 seems happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5420d5a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
